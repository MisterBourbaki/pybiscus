{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Pybiscus: a flexible Federated Learning Framework","text":""},{"location":"#introduction","title":"Introduction","text":"<p>Pybiscus is a simple tool to perform Federated Learning on various models and datasets. It aims at automated as much as possible the FL pipeline, and allows to add virtually any kind of dataset and model.</p> <p>Pybiscus is built on top of Flower, a mature Federated Learning framework; jsonargparse (script and CLI parts) and Lightning/Fabric for all the Machine Learning machinery.</p> <p>The project is still a work-in-progress, and Pybiscus is not yet available as a proper Python package. To use Pybiscus, the best course of action for now is to use Rye, a very powerful comprehensive project and package management solution for Python.</p>"},{"location":"#get-started","title":"Get started","text":"<p>Using Rye, it is as simple as</p> <pre><code>rye sync --all-features\n</code></pre> <p>if you aim at contributing to the project, or simply</p> <pre><code>rye sync\n</code></pre> <p>to install only the core dependencies.</p>"},{"location":"#documentation","title":"Documentation","text":"<p>Documentation is available at docs.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>If you are interested in contributing to the Pybiscus project, start by reading the Contributing guide.</p>"},{"location":"#who-uses-pybiscus","title":"Who uses Pybiscus","text":"<p>Pybiscus is on active development at Thales, both for internal use and on some collaborative projects. One major use is in the Europeean Project PAROMA-MED, dedicated to Federated Learning in the context of medical data distributed among several Hospitals.</p>"},{"location":"#license","title":"License","text":"<p>The License is Apache 2.0. You can find all the relevant information here LICENSE</p>"},{"location":"CONTRIBUTING/","title":"Contributing guidelines","text":""},{"location":"CONTRIBUTING/#filing-issues","title":"Filing issues","text":"<p>File issues using the standard Github issue tracker for the repo.</p>"},{"location":"CONTRIBUTING/#how-to-become-a-contributor-and-submit-your-own-code","title":"How to become a contributor and submit your own code","text":"<ul> <li>Fork the repo and create a dedicated branch.</li> <li>Install pre-commit.</li> <li>Install the dev dependencies.</li> </ul> <p>The code relies on Ruff for formatting and linting, please have a look at the ruff.toml file.</p> <p>There are no tests for now, as it is quite difficult to build suitable test suite for CLI. Unit tests should be added in the future.</p> <p>The repo on GitHub uses GitHub Actions to automate linting/formatting and publishing.</p>"},{"location":"CONTRIBUTING/#contributing-a-patch","title":"Contributing A Patch","text":"<ul> <li>Submit an issue describing your proposed change to the repo in question.</li> <li>The repo owner will respond to your issue promptly.</li> <li>If your proposed change is accepted, and you haven't already done so, sign a Contributor License Agreement (see details above).</li> <li>Fork the desired repo, develop and test your code changes.</li> <li>Submit a pull request.</li> </ul>"},{"location":"Changelog/","title":"Changelog","text":""},{"location":"Changelog/#todo","title":"TODO","text":"<ul> <li>Think about the necessity of Pydantic validation.</li> <li>Refacto of container part.</li> <li>Improve and change the documentation.</li> </ul>"},{"location":"Changelog/#version-080","title":"[Version 0.8.0]","text":"<ul> <li>Refacto:</li> <li>change 'conf_model' into 'model' variable, of type 'LightningModule' to enhance the modularity of the code. The jsonargparse CLI takes care directly of dependency injections.</li> <li>change 'conf_data' into 'data' variable, of type 'LightningDataModule' to enhance the modularity of the code.</li> <li>change 'conf_fabric' into 'fabric' variable, of type 'Fabric' to enhance the modularity of the code. The 'logger' variable is removed. It is now directly defined in the YAML file, using dependency injection.</li> <li>Add a MNIST LightningDataModule, mostly for testing purposes.</li> </ul>"},{"location":"Changelog/#version-070dev1","title":"[Version 0.7.0.dev1]","text":"<ul> <li>Refacto: implement a class Server that holds both all model/data/strategy/fabric instance necessary for the training, and the 'launch' method. Helps a lot with the jsonargparse CLI.</li> <li>Add a new server config file that follows the new CLI for the server part.</li> <li>Remove tests (for now).</li> <li>Adapt github workflow to Rye ; remove/ the test workflow ; remove the publish part.</li> </ul>"},{"location":"Changelog/#version-070dev0","title":"[Version 0.7.0.dev0]","text":"<ul> <li>Bump Typer CLI to jsonargparse. Typer CLI was great to build Pybiscus as a PoC, but it has some limitations: really slow, it does not support configuration files through the arguments of the CLI, you need to rewrite the Pydantic models into the arguments of the CLI... One issue in particular was the difficulty of writing nested configuration directly in the CLI, which is important if you want to easily override parameters in the config file.</li> <li>Remove: helper functions to check the config. Not needed with jsonargparse</li> <li>Add: a toplevel layer 'config_server' or 'config_client' at the top of the configuration files.</li> </ul>"},{"location":"Changelog/#version-061","title":"[Version 0.6.1]","text":"<ul> <li>Fix: Pydantic version, unfortunately pinned to non existing version 2.6.</li> <li>Improve: documentation, still a work in progress.</li> </ul>"},{"location":"Changelog/#version-060dev0","title":"[Version 0.6.0.dev0]","text":"<ul> <li>BREAKING CHANGE Renaming 'src' directory into 'pybiscus' to follow the structure expected by Poetry to properly build the package. First step towards packaging the tool.</li> <li>REFACTO The \"FabricStrategy\" approach is now deprecated. Instead, a few callbacks, based on Fabric and Rich, allows to easily \"upgrade\" the usual weighted average and evaluation functions, for generic Strategies. Note that for now, only the classical FedAvg Strategy provided by Flower has been tested.</li> <li>Starting a small test suite. For now, only test the 'check' parts of client and server applications, on different config files to test good/bad returns.</li> <li>Correcting a bug on the weighted_average function: \"is set()\" had to be replaced by \"==set()\". Metrics are now aggregated and averaged.</li> <li>Introducing a short helper function to merge the configuration from the config file passed as an argument of server or client, and the optional arguments, if passed.</li> </ul>"},{"location":"Changelog/#version-050","title":"[Version 0.5.0]","text":"<ul> <li>Renaming the commands of client and server parts. Improving the help printed by Typer.</li> <li>Adding a new check command for both Server and Client sides in order to possibly check before-hand the validity of the provided configuration file.</li> <li>REFACTO: the main commands of the pybiscus app are now located in src/commands. For instance, the previous version of <code>src/flower/client_fabric.py</code> is split into the Typer part src/commands/app_client.py and the new version of <code>src/flower/client_fabric.py</code>. This helps structure the code into more distinct block.</li> <li>The Unet3D Module comes now with a better Dice Loss and a Dice metric instead of the Accuracy (not suitable in the context of segmentation of 3D images).</li> <li>Small change on the <code>weighted_average</code> function, to take care of the change of keywords.</li> <li>NEW FEATURE: using Trogon to add a Terminal User Interface command to the Pybiscus app. This helps new users to browse through help, existing commands and their syntax.</li> </ul>"},{"location":"Changelog/#version-040","title":"[Version 0.4.0]","text":"<ul> <li>the Server has now the possibility to save the weights of the model at the end of the FL session.</li> <li>add the possibility to perform a pre train validation loop on the Client. This feature allows to perform one validation loop, on the validation dataset holds by the client, of the newly sent, aggregated weights.</li> <li> <p>updating the Lightning version needed: not \"all\" anymore, just \"pytorch-extra\" in order to have way less dependencies to install and check.</p> </li> <li> <p>NEW FEATURE: using Pydantic to validate ahead of time the configuration given to the CLI:</p> <ul> <li>data config validation</li> <li>model config validaton</li> <li>server config validation</li> <li>client config validation</li> <li>Fabric config validation</li> <li>Streategy config validation</li> </ul> </li> <li>adding some documentation for the use of config files.</li> <li>updating the documentation on various classes and functions.</li> </ul>"},{"location":"Changelog/#version-033","title":"[Version 0.3.3]","text":"<ul> <li>moving loops_fabric.py into ml directory (a better place)</li> <li>getting rid of load_data_paroma, amd replaces it by direct use of LightningDataModule.</li> <li>updating config files accordingly</li> <li>moving logging of evaluate function to evaluate inside FabricStrategy; more coherence with aggregate_fit and aggregate_evaulate.</li> <li>upgrading the config for local training with key 'trainer', making all Trainer arguments virtually available</li> <li>adding a constraint on deepspeed library due to some issues with the installation of the wheel. Issue with poetry? In poetry, version is 0.9.0 but in installing the wheel built by poetry, it is 0.11.1...</li> </ul>"},{"location":"ROADMAP/","title":"Features","text":""},{"location":"ROADMAP/#work-in-progress","title":"Work in Progress","text":"<ul> <li>[ ] Putting model and data referenced in Strategy outside of it: Strategies do not depend on model or data, only on aggregation functions. Instead, writing some wrappers on aggregation functions to take care of any model/data, using Fabric.</li> <li>[x] Writing wrappers for logging (both via Rich and Tensorboard). SHould not been done via rewriting the functions inside the Strategy.</li> <li>[ ] Working on importing dynamically other LightingModules.</li> <li>[ ] Working on providing a better package, with both CLI available, and the possibility of using directly the wrappers or the Client.</li> <li>[ ] Improving the Documentation part and docstrings of the code.</li> <li>[x] GitHub Pages available.</li> <li>[ ] Adding some other datasets and models: see point above.</li> <li>[x] Adding a test suite using pytest: see here https://typer.tiangolo.com/tutorial/testing/</li> <li>[x] Thoughts on Checkpointing.</li> <li>[ ] Adding commands to deal with data downloading and/or preprocessing?</li> <li>[ ] Integration of Differential Privacy.</li> <li>[ ] Integration of FHE</li> <li>[ ] Adding other strategies:<ul> <li>FedProx</li> <li>...</li> </ul> </li> <li>[x] Refacto: splitting flower directory into flower and typer parts. Separating commands themselves from code of Flower.</li> <li>[ ] Better logging: fusion between logging through Rich Console and logging from Flower?</li> <li>[x] Use Pydantic to control config files and the good use of the different tools.</li> <li>[x] Adding the possibility to save the weights of the model. Cane be done using Fabric.</li> <li>[x] Working on Docker part.</li> <li>[x] Using only LightningDataModule, and getting rid of load_data.</li> <li>[x] Logging with tensorboard.</li> </ul> <p>## Road Map</p> <p>Here is a list of more mid/long term ideas to implement in Pybiscus for Federated Learning.</p>"},{"location":"configuration/","title":"How to use config files","text":"<p>Here are a few hints about how to use and customize the config files (server, client).</p>"},{"location":"configuration/#fabric","title":"Fabric","text":"<p>The keyword <code>fabric</code> holds a dictionnary of keywords to use by the Fabric instance. It is used by both Server and Clients. The keywords and their types are simply the one provided by the Fabric API.</p> <p>Here is an example from the file <code>configs/server.yml</code>:</p> <pre><code>...\nfabric:\n  accelerator: gpu\n  devices:\n    - 0\n...\n</code></pre> <p>The keyword <code>devices</code> is waiting for either a list of integers (the id of the devices themselves) or an integer (for the number of devices wanted). To use CPU for instance, you can simply write</p> <pre><code>...\nfabric:\n  accelerator: cpu\n  # devices:\n...\n</code></pre> <p>The keyword <code>devices</code> is left intentionnaly commented, as Fabric will automatically find a suitable device corresponding to the choice cpu.</p>"},{"location":"configuration/#models","title":"Models","text":"<p>Thanks to jsonargparse and its ability to handle dependency injection, any LightningModule can be used with Pybiscus. It just needs to be either install via a Python library, in the same virtual environment as Pybiscus, or accessible via the path.</p> <p>In the <code>server.yml</code> configuration file available (and in the client files too), the model is defined by</p> <pre><code>...\nmodel:\n  class_path: pybiscus.ml.models.cnn.lit_cnn.LitCNN\n  init_args:\n    input_shape: 3\n    mid_shape: 6\n    n_classes: 10\n    lr: 0.001\n...\n</code></pre> <p>which means that the CLI will use the LightningModule at the path <code>pybiscus.ml.models.cnn.lit_cnn.LitCNN</code>, and use the arguments passed after the <code>init_args</code> keyword.</p> <p>To use a different model, available in the Python path, change the <code>class_path</code> to point to your model, and change the <code>init_args</code> accordingly.</p>"},{"location":"configuration/#data","title":"Data","text":"<p>(see Models)</p>"},{"location":"configuration/#others","title":"Others","text":""},{"location":"container/","title":"Docker","text":"<p>THIS IS A HIGHLY WIP STILL !!!</p> <p>To build the image (which is quite heavy as of now), do the following</p> <pre><code>cd container\ndocker build . -t pybiscus:app.v0.5.0\n</code></pre> <p>If you are working under a proxy, you might need to add some argument for the buid</p> <pre><code>cd container\ndocker build \\\n--build-arg http_proxy=$HTTP_PROXY \\\n--build-arg https_proxy=$HTTPS_PROXY \\\n--build-arg no_proxy=$NO_PROXY \\\n. -t pybiscus:app.v0.5.0\n</code></pre> <p>Then, again only if you have to go through a proxy for internet access, then to download the data the different containers will need and internet access. So you need to set the file <code>~/.docker/config.json</code> with the proxy config</p> <p>For the client to be able to communicate with the server you need to add \"server\" to ne noProxy config.</p> <pre><code>{\n        \"proxies\":{\n                \"default\":{\n                        \"httpsProxy\": \"your_httpsProxy\",\n                        \"httpProxy\": \"your_httpProxy\",\n                        \"noProxy\": \"your_noProxy,server\",\n                }\n        }\n}\n</code></pre> <p>and voila! The docker image is aimed at running only the pybiscus_app itself. In order to facilitate the use of docker (which can be quite verbose), some scripts are available in container/scripts. To launch a local training, you just need to update <code>container/scripts/launch_local_train.sh</code> and <code>container/configs/local_train.yml</code> according to where are located your datasets and such. Then, simply run</p> <pre><code>bash container/scripts/launch_local_train.sh\n</code></pre> <p>It is as simple as running</p> <pre><code>docker run -t --gpus device=(some_device) -v \"$(pwd)\":/app/datasets pybiscus:app --help\n</code></pre> <p>to get the help of the app. The short version is, <code>docker run -t pybiscus:app.v0.5.0</code> is equivalent to running <code>pybiscus_app</code>. As for the app itself, the docker image can launch either client, server or local components.</p> <p>To launch a \"true\" Federated learning, you need first to create a docker network for the containers to communicate:</p> <pre><code>docker network create federated\n</code></pre> <p>then</p> <pre><code>bash container/scripts/launch_server.sh\n</code></pre> <p>followed by (in other terminal)</p> <pre><code>bash container/scripts/launch_client_1.sh\n</code></pre> <p>and</p> <pre><code>bash container/scripts/launch_client_2.sh\n</code></pre>"},{"location":"getting_started/","title":"Pybiscus","text":"<p>A simple tool to perform Federated Learning on various models and datasets. Build on top of Flower (FL part), jsonargparse (script and CLI parts) and Lightning/Fabric (ML part).</p>"},{"location":"getting_started/#uses-of-pybiscus","title":"Uses of Pybiscus","text":"<p>You have two ways of using Pybiscus. Either by cloning the repo and installing (using Rye) all dependencies, and working on the code itself; or (in a later version) by just downloading the wheel and installing as a package.</p>"},{"location":"getting_started/#installation","title":"Installation","text":"<p>Using Rye, it is as simple as</p> <pre><code>rye sync --all-features\n</code></pre> <p>if you aim at contributing to the project, or simply</p> <pre><code>rye sync\n</code></pre> <p>to install only the core dependencies.</p>"},{"location":"getting_started/#basic-usage","title":"Basic usage","text":"<p>The Pybiscus project comes with two applications, <code>pybiscus_server</code> and <code>pybiscus_client</code>. You can test if everything is working by running</p> <pre><code>rye run pybiscus_server --help\n</code></pre> <p>or, if you activated the virtual environnement created automatically by Rye</p> <pre><code>(.venv) pybiscus_server --help\n</code></pre> <p>For the client side, run</p> <pre><code>rye run pybiscus_client --help\n</code></pre> <p>Both server and client applications come with an <code>init</code> method that basically initializes the core Python class dedicated to the server or the client. The app <code>pybiscus_server</code> has a method <code>launch</code> to launch the Flower Server. The client app <code>pybiscus_client</code> has a method <code>start</code> to start a Flower Client.</p> <p>The best way to use both CLI is by using directly a YAML configuration file, which holds all arguments necessary for launching a Federated training. Some templates are in the <code>configs/</code> folder.</p> <p>To launch a full Federated training, for instance with the three clients whose configuration files are in <code>configs/</code>, you need to open four terminal windows and run successively</p> <pre><code>rye run pybiscus_server --config configs/server.yml\nrye run pybiscus_client --config configs/client_1.yml\nrye run pybiscus_client --config configs/client_2.yml\nrye run pybiscus_client --config configs/client_3.yml\n</code></pre> <p>This will run a two-rounds training on a simple CNN model, using the classicla CIFAR10 dataset. This will run on CPU for all server and clients. To run on GPU, you can simply change the configuration files, as documented here.</p>"},{"location":"getting_started/#features","title":"Features","text":""},{"location":"getting_started/#work-in-progress","title":"Work in Progress","text":"<ul> <li> <p>[ ] Improving the Documentation part (Sphinx ?) and docstrings of the code.</p> </li> <li> <p>[ ] Implementation of the Simulation part of Flower.</p> </li> <li> <p>[ ] Organizing dependencies in pyproject.toml: dep from Typer/Flower/Fabric part (the core), dep from Paroma, dep from next data/model.</p> </li> <li> <p>[ ] Integration of Differential Privacy.</p> </li> <li> <p>[ ] Using only LightningDataModule, and getting rid of load_data.</p> </li> <li> <p>[x] Logging with tensorboard.</p> </li> </ul>"},{"location":"getting_started/#road-map","title":"Road Map","text":"<p>Here is a list of more mid/long term ideas to implement in Pybiscus for Federated Learning.</p>"},{"location":"logging/","title":"Loggings","text":""},{"location":"logging/#tensorboard-logging","title":"Tensorboard logging","text":"<p>Thanks to Fabric and wrappers, a Tensorboard is instantiates on the server side to check on the training, using all metrics sent by the clients.</p> <p>The tensorboard is available (on the server side) by running:</p>"},{"location":"logging/#rich-logging","title":"Rich Logging","text":"<p>Pybiscus use the Rich Console to print beautifully some informations on both server and client sides during training, in addition to the already existant logging by Flower.</p>"}]}