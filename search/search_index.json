{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Pybiscus: a flexible Federated Learning Framework","text":""},{"location":"#introduction","title":"Introduction","text":"<p>Pybiscus is a simple tool to perform Federated Learning on various models and datasets. It aims at automated as much as possible the FL pipeline, and allows to add virtually any kind of dataset and model.</p> <p>Pybiscus is built on top of Flower, a mature Federated Learning framework; Typer (script and CLI parts) and Lightning/Fabric for all the Machine Learning machinery.</p> <p>You can simply test Pybiscus by downloading the latest wheel available and install it.</p>"},{"location":"#get-started","title":"Get started","text":"<p>You can simply test Pybiscus by downloading the latest wheel available in the dist folder and install it in a virtual environnement:</p> <pre><code>python -m pip install virtualenv\npython -m virtualenv .venv\nsource .venv/bin/activate\n(.venv) python -m pip install pybiscus_paroma-0.5.0-py3-none-any.whl\n</code></pre> <p>and you are good to go! The packages comes with an app named <code>pybiscus_paroma_app</code> that you can use in the virtual environment. You can then test if everything went well by launching a local training:</p> <pre><code>(.venv) pybiscus_paroma_app local train-config configs/local_train.yml\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>Documentation is available at docs.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>If you are interested in contributing to the Pybiscus project, start by reading the Contributing guide.</p>"},{"location":"#who-uses-pybiscus","title":"Who uses Pybiscus","text":"<p>Pybiscus is on active development at Thales, both for internal use and on some collaborative projects. One major use is in the Europeean Project PAROMA-MED, dedicated to Federated Learning in the context of medical data distributed among several Hospitals.</p>"},{"location":"#license","title":"License","text":"<p>The License is Apache 2.0. You can find all the relevant information here LICENSE</p>"},{"location":"CONTRIBUTING/","title":"Contributing guidelines","text":""},{"location":"CONTRIBUTING/#filing-issues","title":"Filing issues","text":"<p>File issues using the standard Github issue tracker for the repo.</p>"},{"location":"CONTRIBUTING/#how-to-become-a-contributor-and-submit-your-own-code","title":"How to become a contributor and submit your own code","text":""},{"location":"CONTRIBUTING/#contributing-a-patch","title":"Contributing A Patch","text":"<ul> <li>Submit an issue describing your proposed change to the repo in question.</li> <li>The repo owner will respond to your issue promptly.</li> <li>If your proposed change is accepted, and you haven't already done so, sign a Contributor License Agreement (see details above).</li> <li>Fork the desired repo, develop and test your code changes.</li> <li>Submit a pull request.</li> </ul>"},{"location":"Changelog/","title":"Changelog","text":""},{"location":"Changelog/#unreleased","title":"[Unreleased]","text":"<ul> <li>Correcting a bug on the weighted_average function: \"is set()\" had to be replaced by \"==set()\". Metrics are now aggregated and averaged.</li> <li>Introducing a short helper function to merge the configuration from the config file passed as an argument of server or client, and the optional arguments, if passed.</li> </ul>"},{"location":"Changelog/#version-050","title":"[Version 0.5.0]","text":"<ul> <li>Renaming the commands of client and server parts. Improving the help printed by Typer.</li> <li>Adding a new check command for both Server and Client sides in order to possibly check before-hand the validity of the provided configuration file.</li> <li>REFACTO: the main commands of the pybiscus app are now located in src/commands. For instance, the previous version of <code>src/flower/client_fabric.py</code> is split into the Typer part src/commands/app_client.py and the new version of <code>src/flower/client_fabric.py</code>. This helps structure the code into more distinct block.</li> <li>The Unet3D Module comes now with a better Dice Loss and a Dice metric instead of the Accuracy (not suitable in the context of segmentation of 3D images).</li> <li>Small change on the <code>weighted_average</code> function, to take care of the change of keywords.</li> <li>NEW FEATURE: using Trogon to add a Terminal User Interface command to the Pybiscus app. This helps new users to browse through help, existing commands and their syntax.</li> </ul>"},{"location":"Changelog/#version-040","title":"[Version 0.4.0]","text":"<ul> <li>the Server has now the possibility to save the weights of the model at the end of the FL session.</li> <li>add the possibility to perform a pre train validation loop on the Client. This feature allows to perform one validation loop, on the validation dataset holds by the client, of the newly sent, aggregated weights.</li> <li> <p>updating the Lightning version needed: not \"all\" anymore, just \"pytorch-extra\" in order to have way less dependencies to install and check.</p> </li> <li> <p>NEW FEATURE: using Pydantic to validate ahead of time the configuration given to the CLI:</p> <ul> <li>data config validation</li> <li>model config validaton</li> <li>server config validation</li> <li>client config validation</li> <li>Fabric config validation</li> <li>Streategy config validation</li> </ul> </li> <li>adding some documentation for the use of config files.</li> <li>updating the documentation on various classes and functions.</li> </ul>"},{"location":"Changelog/#version-033","title":"[Version 0.3.3]","text":"<ul> <li>moving loops_fabric.py into ml directory (a better place)</li> <li>getting rid of load_data_paroma, amd replaces it by direct use of LightningDataModule.</li> <li>updating config files accordingly</li> <li>moving logging of evaluate function to evaluate inside FabricStrategy; more coherence with aggregate_fit and aggregate_evaulate.</li> <li>upgrading the config for local training with key 'trainer', making all Trainer arguments virtually available</li> <li>adding a constraint on deepspeed library due to some issues with the installation of the wheel. Issue with poetry? In poetry, version is 0.9.0 but in installing the wheel built by poetry, it is 0.11.1...</li> </ul>"},{"location":"ROADMAP/","title":"Features","text":""},{"location":"ROADMAP/#work-in-progress","title":"Work in Progress","text":"<ul> <li>[ ] Putting model and data referenced in Strategy outside of it: Strategies do not depend on model or data, only on aggregation functions. Instead, writing some wrappers on aggregation functions to take care of any model/data, using Fabric.</li> <li>[ ] Writing wrappers for logging (both via Rich and Tensorboard). SHould not been done via rewriting the functions inside the Strategy.</li> <li>[ ] Working on importing dynamically other LightingModules.</li> <li>[ ] Working on providing a better package, with both CLI available, and the possibility of using directly the wrappers or the Client.</li> <li>[ ] Improving the Documentation part and docstrings of the code.</li> <li>[ ] GitHub Pages available.</li> <li>[ ] Adding some other datasets and models: see point above.</li> <li>[ ] Adding a test suite using pytest: see here https://typer.tiangolo.com/tutorial/testing/</li> <li>[x] Thoughts on Checkpointing.</li> <li>[ ] Adding commands to deal with data downloading and/or preprocessing?</li> <li>[ ] Integration of Differential Privacy.</li> <li>[ ] Integration of FHE</li> <li>[ ] Adding other strategies:<ul> <li>FedProx</li> <li>...</li> </ul> </li> <li>[x] Refacto: splitting flower directory into flower and typer parts. Separating commands themselves from code of Flower.</li> <li>[ ] Better logging: fusion between logging through Rich Console and logging from Flower?</li> <li>[x] Use Pydantic to control config files and the good use of the different tools.</li> <li>[x] Adding the possibility to save the weights of the model. Cane be done using Fabric.</li> <li>[x] Working on Docker part.</li> <li>[x] Using only LightningDataModule, and getting rid of load_data.</li> <li>[x] Logging with tensorboard.</li> </ul> <p>## Road Map</p> <p>Here is a list of more mid/long term ideas to implement in Pybiscus for Federated Learning.</p>"},{"location":"configuration/","title":"How to use config files","text":"<p>Here are a few hints about how to use and customize the config files (server, client).</p>"},{"location":"configuration/#fabric","title":"Fabric","text":"<p>The keyword <code>fabric</code> holds a dictionnary of keywords to use by the Fabric instance. It is used by both Server and Clients. The keywords and their types are simply the one provided by the Fabric API.</p> <p>Here is an example from the file <code>configs/server.yml</code>:</p> <pre><code>...\nfabric:\n  accelerator: gpu\n  devices:\n    - 0\n...\n</code></pre> <p>The keyword <code>devices</code> is waiting for either a list of integers (the id of the devices themselves) or an integer (for the number of devices wanted). To use CPU for instance, you can simply write</p> <pre><code>...\nfabric:\n  accelerator: cpu\n  # devices:\n...\n</code></pre> <p>The keyword <code>devices</code> is left intentionnaly commented, as Fabric will automatically find a suitable device corresponding to the choice cpu.</p>"},{"location":"configuration/#models","title":"Models","text":"<p>Please look at ::: src.flower.server_fabric.evaluate_config     options:       heading_level: 3</p> <p>and</p> <p>::: src.flower.server_fabric.launch_config</p>"},{"location":"configuration/#data","title":"Data","text":""},{"location":"configuration/#others","title":"Others","text":""},{"location":"getting_started/","title":"Pybiscus","text":"<p>A simple tool to perform Federated Learning on various models and datasets. Build on top of Flower (FL part), Typer (script and CLI parts) and Lightning/Fabric (ML part).</p>"},{"location":"getting_started/#uses-of-pybiscus","title":"Uses of Pybiscus","text":"<p>You have two ways of using Pybiscus. Either by cloning the repo and installing (via Poetry) all dependencies, and working on the code itself; or by just downloading the wheel and installing as a package.</p>"},{"location":"getting_started/#user-mode","title":"User Mode","text":"<p>The wheel in <code>dist/pybiscus-0.5.0-py3-none-any.whl</code> is the packaged version of Pybiscus. You can download it and do</p> <pre><code>pyenv local 3.9.12\npython -m pip install virtualenv\npython -m virtualenv .venv\nsource .venv/bin/activate\n(.venv) pip install dist/pybiscus-0.4.0-py3-none-any.whl\n</code></pre> <p>The Pybiscus project comes with an handy app, dubbed pybiscus_app. You can test it directly as it is installed in your virtual env:</p> <pre><code>(.venv) pybiscus_app --help\n</code></pre> <p>this command will show you some documentation on how to use the app. There are three main commands:</p> <ul> <li> <p>server is dedicated to the server side;</p> </li> <li> <p>client, to the client side;</p> </li> <li> <p>local is for local, classical training as a way to compare to the Federated version (if need be)</p> </li> </ul> <p>Note that the package is still actively under development, and even if we try as much as possible to not break things, it could happen!</p> <p>To work, the app needs only config files for the server and the clients. Any number of clients can be launched, using the same command <code>client launch</code>. or, now with config files (examples are provided in <code>configs/</code>):</p> <pre><code>pybiscus_app server launch path-to-config/server.yml\npybiscus_app client launch path-to-config/client_1.yml\npybiscus_app client launch path-to-config/client_2.yml\n</code></pre> <p>Here is the API for the server, for instance: ::: src.flower.server_fabric.launch_config</p>"},{"location":"getting_started/#dev-mode","title":"Dev Mode","text":"<p>We strongly suggest the use of both pyenv and poetry.</p> <ul> <li> <p>Pyenv is a tool to manage properly Python versions, and you can find install instructions here https://github.com/pyenv/pyenv#installation.</p> </li> <li> <p>Poetry is a dependency tool, way better than the usual \"pip install -r requirements.txt\" paradigm, and manages virtual environments too. It is easy to use, well documented, and the install instructions are here https://python-poetry.org/docs/#installation.</p> </li> </ul> <p>Once those tools are installed, clone the whole repo, and do</p> <pre><code>pyenv local 3.9.12  # the code has only been tested for this python version\npoetry install\n</code></pre> <p>and you are good to go! We suggest to create a directory <code>experiments</code> to hold checkpoints and other artefacts and a directory <code>datasets</code> to hold the data.</p>"},{"location":"getting_started/#docker","title":"Docker","text":"<p>To build the image (which is quite heavy as of now), do the following</p> <pre><code>cd container\ndocker build . -t pybiscus:app.v0.5.0\n</code></pre> <p>If you are working under a proxy, you might need to add some argument for the buid</p> <pre><code>cd container\ndocker build \\\n--build-arg http_proxy=$HTTP_PROXY \\\n--build-arg https_proxy=$HTTPS_PROXY \\\n--build-arg no_proxy=$NO_PROXY \\\n. -t pybiscus:app.v0.5.0\n</code></pre> <p>Then, again only if you have to go through a proxy for internet access, then to download the data the different containers will need and internet access. So you need to set the file <code>~/.docker/config.json</code> with the proxy config</p> <p>For the client to be able to communicate with the server you need to add \"server\" to ne noProxy config.</p> <pre><code>{\n        \"proxies\":{\n                \"default\":{\n                        \"httpsProxy\": \"your_httpsProxy\",\n                        \"httpProxy\": \"your_httpProxy\",\n                        \"noProxy\": \"your_noProxy,server\",\n                }\n        }\n}\n</code></pre> <p>and voila! The docker image is aimed at running only the pybiscus_app itself. In order to facilitate the use of docker (which can be quite verbose), some scripts are available in container/scripts. To launch a local training, you just need to update <code>container/scripts/launch_local_train.sh</code> and <code>container/configs/local_train.yml</code> according to where are located your datasets and such. Then, simply run</p> <pre><code>bash container/scripts/launch_local_train.sh\n</code></pre> <p>It is as simple as running</p> <pre><code>docker run -t --gpus device=(some_device) -v \"$(pwd)\":/app/datasets pybiscus:app --help\n</code></pre> <p>to get the help of the app. The short version is, <code>docker run -t pybiscus:app.v0.5.0</code> is equivalent to running <code>pybiscus_app</code>. As for the app itself, the docker image can launch either client, server or local components.</p> <p>To launch a \"true\" Federated learning, you need first to create a docker network for the containers to communicate:</p> <pre><code>docker network create federated\n</code></pre> <p>then</p> <pre><code>bash container/scripts/launch_server.sh\n</code></pre> <p>followed by (in other terminal)</p> <pre><code>bash container/scripts/launch_client_1.sh\n</code></pre> <p>and</p> <pre><code>bash container/scripts/launch_client_2.sh\n</code></pre>"},{"location":"getting_started/#features","title":"Features","text":""},{"location":"getting_started/#work-in-progress","title":"Work in Progress","text":"<ul> <li> <p>[ ] Improving the Documentation part (Sphinx ?) and docstrings of the code.</p> </li> <li> <p>[ ] Implementation of the Simulation part of Flower.</p> </li> <li> <p>[ ] Organizing dependencies in pyproject.toml: dep from Typer/Flower/Fabric part (the core), dep from Paroma, dep from next data/model.</p> </li> <li> <p>[ ] Integration of Differential Privacy.</p> </li> <li> <p>[ ] Using only LightningDataModule, and getting rid of load_data.</p> </li> <li> <p>[x] Logging with tensorboard.</p> </li> </ul>"},{"location":"getting_started/#road-map","title":"Road Map","text":"<p>Here is a list of more mid/long term ideas to implement in Pybiscus for Federated Learning.</p>"},{"location":"how-to/","title":"How-tos","text":"<p>Here are a few guides to update Pybiscus with new datasets, and models, and such.</p>"},{"location":"how-to/#how-to-add-models-in-pybiscus","title":"How to add models in Pybiscus","text":"<p>Available models are located in <code>ml/models/</code>. To add a new model, follow the few points below:</p> <ul> <li>make a new subdirectory, like <code>ml/models/my-model/</code></li> <li>create two files <code>my_model.py</code> and <code>lit_my_model.py</code>:<ul> <li>the first one contains the usual PyTorch NN Module that defines your model.</li> <li>the second one contains the LightningModule based on the classical nn.module.</li> </ul> </li> <li>if needed, add another directory <code>ml/models/my-model/all-things-needed/</code> which would contain all things necessary for your model to work properly: specific losses and metrics, dedicated torch modules, and so on.</li> <li>update the file <code>ml/registry.py</code>:<ul> <li>import your LightningModule;</li> <li>update <code>model_registry</code> by adding a new key linking to your LightingModule.</li> </ul> </li> </ul>"},{"location":"how-to/#how-to-add-datasets-in-pybiscus","title":"How to add datasets in Pybiscus","text":"<p>Available datasets are located in <code>ml/data/</code>. To add a new model, follow the few points below:</p> <ul> <li>make a new subdirectory, like <code>ml/data/my-data/</code></li> <li>create two files <code>my_data.py</code> and <code>lit_my_data.py</code>:<ul> <li>the first one contains the usual PyTorch Dataset that defines your dataset.</li> <li>the second one contains the LightningDataModule based on the classical torch.dataset.</li> </ul> </li> <li>if needed, add another directory <code>ml/data/my-data/all-things-needed/</code> which would contain all things necessary for your dataset to work properly, in particular preprocessing.</li> <li>update the file <code>ml/registry.py</code>:<ul> <li>import your LightningDataModule;</li> <li>update <code>datamodule_registry</code> by adding a new key linking to your LightingDataModule.</li> </ul> </li> </ul>"}]}